---
title: "Demonstrating Literate R"
author: "Jim Tyson"
date: "4 April 2016"
bibliography: bibliography.bib
output:
  revealjs::revealjs_presentation:
    theme: sky
    highlight: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Literate Programming and Reproducible Research
Reproducibility is the minimum standard for research.  Broman says

_Computational work is reproducible if one can take the data and code and produce the same set of results. Replicable is more stringent: can someone  repeat the experiment and get the same results?_
 
[see @bromantpr]

-------------------------------------

And Peng in his presentation _Make the World a Better Place through Reproducible Research_ speaks of *Reproducible Research: A Minimum Standard* with the following characteristics

  * Published research where the following are made available:
  * Analytic data
  * Computer code implementing methods
  * Documentation about code/data

All are distributed using standard means

[see @rdpengrr]

## What could go wrong?

You could just make a fool of yourself on a wiki page:

[embarrassing chi square fail](https://en.wikibooks.org/wiki/Statistics_Ground_Zero/Association)

Or you could get called out by a persistent graduate student:

[strict austerity, less strict data checking](http://www.bbc.co.uk/news/magazine-22223190)



##Literate Programming 

In this context, _literate programming_ [see @knuth_literate_1984] is seen as part of a workflow for _reproducible research_ by allowing a report on the results of research to be disseminated along with the computational code that produced the analysis.

##The tools
### Rstudio to write and run r scripts and markdown files
As well as being a nice environment in which to run R and develop R scripts, RStudio will render rmarkdown documents for you.

![The rmardown document creation process](RMarkdownFlow.png)

##The tools
### Gnu make to specify how products are to be assembled
Gnu make will allow you to assemble the files that make up your project correctly and efficiently and provide others with a complete guide to how you created your research products.

<img src="makefile.png" style="width: 350px;"/>

##The tools
### Git and git hub for version control
Git will help you manage the development process and with git hub you can manage the project remotely - when you make changes locally you can merge them with the online repository.  This facilitates collaboration and mobile working.

<img src="git-and-github-workflow.png" style="width: 350px;"/>

##Some Principles (when using RStudio at least...)

* Use packrat
* Data is read only
* Everything is scripted
* Be modular
* Automate with _make_
* Use version control
* Disseminate code, data and reports

##Use packrat and always create projects

Always create a project - either manually or using RStudio.  Keep all the files required for your product within the project folder structure.  Use packrat to ensure that your project is truly portable and won't fail if moved to an environment where some packages have not been installed.

## Treat data as read only

Read the raw data and process it by script each time.  You can programmatically create a new datafile if you wish or directly create and work with the processed data as a dataframe.  By leaving the original data in its raw state and by scripting any data cleaning and data preparation, you will never have to worry about losing your data files or worrying which of multiple files contains the correct up to date data.

## Script everything

All R processes should be run from scripts.  This means that you always know exactly what has been done to the data.  You can easily correct errors.  Your audience can see exactly what you did.  You can repeat your data preparation and analysis easily.  If you make a mistake in analysis or preparation and you dirty your data, you can simply re-run your scipts up to that point to recover.

## Be modular

There is no absolute rule about modularity, but as an example, I have separated the data preparation and the production of graphs into separate scripts.  This means that I have quite small code files to deal with and I can run only the code that needs to be run easily.  This becomes much more useful when you _automate your workflow_.

## Automate the workflow

Create a *make* file to specify how your product - usually a report - is to be produced.  The unix __make__ utility specifies _target files_ to be produced, their _dependencies_ and the _recipe_ to create them.  When you execute the _Makefile_ the utility checks timestamps and only runs the files that have changed since the target was last produced.

## Use version control

If you have __git__ installed, it is very easy to place your project under version control.  Here is the basic process for creating a repository using _git_ and _github_.

## Make all products available to your audience

Reproducibility is only achieved if you make the code and data accessible to your audience.  Github provides an excellent way to do this.  Create a public repository for the project.

# References
